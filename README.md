# Longchain-MCP

ğŸ§  Milestone 1: Streaming Response (Typewriter Experience)
ğŸ¯ Goal

Enable streaming responses from the backend to the frontend so that users can see the AI's reply as it is being generated, similar to the typing effect in ChatGPT
.

ğŸ§­ Feature Breakdown
Feature	Description	Status
1. LLM streaming function	Use astream() to stream tokens from the LLM	âœ…
2. FastAPI streaming route	Return StreamingResponse instead of one-shot text	âœ…
3. CORS support	Allow frontend (React) to access API from another origin	âœ…
4. Fetch streaming in React	Consume token stream using ReadableStream	âœ…
5. Live output rendering	Append streamed text in real time	âœ…
6. Loading state	Disable button and show â€œStreamingâ€¦â€ while in progress	âœ…
7. Error handling	Show error message on failure	âœ…
8. Auto scroll	Keep output box scrolled to the bottom while streaming	âœ…
9. Documentation	This README ğŸ˜	âœ…
ğŸ§° Tech Stack

Backend: FastAPI + LangChain (Azure OpenAI)

Frontend: React + Fetch API streaming

LLM: GPT-4.1-nano via Azure OpenAI Service

Styling: Custom CSS (Dark Mode UI)
