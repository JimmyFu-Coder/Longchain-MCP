# app/services/azure_search_service.py
import json
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime

from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from azure.search.documents.indexes.models import (
    SearchIndex,
    SimpleField,
    SearchableField,
    SearchField,
    VectorSearch,
    HnswAlgorithmConfiguration,
    VectorSearchProfile,
    SemanticConfiguration,
    SemanticSearch,
    SemanticPrioritizedFields,
    SemanticField,
    SearchFieldDataType,
)
from azure.core.credentials import AzureKeyCredential
from langchain_openai import AzureOpenAIEmbeddings

from app.core.config import settings


class AzureSearchService:
    """Azure AI Search æœåŠ¡ï¼ŒåŒ…å« embedding ç”Ÿæˆå’Œå‘é‡æœç´¢åŠŸèƒ½"""

    def __init__(self):
        # Azure AI Search å®¢æˆ·ç«¯
        self.search_client = SearchClient(
            endpoint=settings.azure_search_endpoint,
            index_name=settings.azure_search_index_name,
            credential=AzureKeyCredential(settings.azure_search_key)
        )

        self.index_client = SearchIndexClient(
            endpoint=settings.azure_search_endpoint,
            credential=AzureKeyCredential(settings.azure_search_key)
        )

        # Azure OpenAI Embedding å®¢æˆ·ç«¯
        self.embedding_client = AzureOpenAIEmbeddings(
            api_key=settings.azure_openai_api_key,
            azure_endpoint=settings.azure_openai_endpoint,
            deployment=settings.azure_openai_embedding_deployment,
            api_version=settings.azure_openai_embedding_api_version,
            chunk_size=1000
        )

    async def ensure_index_exists(self) -> bool:
        """ç¡®ä¿æœç´¢ç´¢å¼•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        try:
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            try:
                self.index_client.get_index(settings.azure_search_index_name)
                print(f"âœ… ç´¢å¼• '{settings.azure_search_index_name}' å·²å­˜åœ¨")
                return True
            except Exception:
                print(f"ç´¢å¼• '{settings.azure_search_index_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")

            # åˆ›å»ºç´¢å¼•
            fields = [
                SimpleField(
                    name="id",
                    type=SearchFieldDataType.String,
                    key=True,
                    filterable=True,
                ),
                SearchableField(
                    name="content",
                    type=SearchFieldDataType.String,
                    searchable=True,
                    retrievable=True,
                ),
                SearchField(
                    name="content_vector",
                    type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                    searchable=True,
                    vector_search_dimensions=settings.embedding_dimension,
                    vector_search_profile_name="my-vector-config",
                ),
                SimpleField(
                    name="title",
                    type=SearchFieldDataType.String,
                    filterable=True,
                    searchable=True,
                ),
                SimpleField(
                    name="file_path",
                    type=SearchFieldDataType.String,
                    filterable=True,
                ),
                SimpleField(
                    name="chunk_index",
                    type=SearchFieldDataType.Int32,
                    filterable=True,
                ),
                SimpleField(
                    name="quality_score",
                    type=SearchFieldDataType.Double,
                    filterable=True,
                    sortable=True,
                ),
                SimpleField(
                    name="created_at",
                    type=SearchFieldDataType.DateTimeOffset,
                    filterable=True,
                    sortable=True,
                ),
                SimpleField(
                    name="metadata",
                    type=SearchFieldDataType.String,
                    retrievable=True,
                ),
            ]

            # å‘é‡æœç´¢é…ç½®
            vector_search = VectorSearch(
                algorithms=[
                    HnswAlgorithmConfiguration(
                        name="my-hnsw-config",
                        parameters={
                            "m": 4,
                            "efConstruction": 400,
                            "efSearch": 500,
                            "metric": "cosine"
                        }
                    )
                ],
                profiles=[
                    VectorSearchProfile(
                        name="my-vector-config",
                        algorithm_configuration_name="my-hnsw-config",
                    )
                ]
            )

            # è¯­ä¹‰æœç´¢é…ç½®
            semantic_config = SemanticConfiguration(
                name="my-semantic-config",
                prioritized_fields=SemanticPrioritizedFields(
                    content_fields=[
                        SemanticField(field_name="content")
                    ],
                    title_field=SemanticField(field_name="title")
                )
            )

            semantic_search = SemanticSearch(
                configurations=[semantic_config]
            )

            # åˆ›å»ºç´¢å¼•
            index = SearchIndex(
                name=settings.azure_search_index_name,
                fields=fields,
                vector_search=vector_search,
                semantic_search=semantic_search,
            )

            result = self.index_client.create_index(index)
            print(f"âœ… æˆåŠŸåˆ›å»ºç´¢å¼•: {result.name}")
            return True

        except Exception as e:
            print(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {str(e)}")
            return False

    async def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """ä½¿ç”¨ Azure OpenAI ç”Ÿæˆæ–‡æœ¬å‘é‡"""
        try:
            embeddings = await self.embedding_client.aembed_documents(texts)
            return embeddings
        except Exception as e:
            print(f"âŒ ç”Ÿæˆembeddingså¤±è´¥: {str(e)}")
            return [[0.0] * settings.embedding_dimension for _ in texts]

    async def generate_single_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„å‘é‡"""
        try:
            embedding = await self.embedding_client.aembed_query(text)
            return embedding
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå•ä¸ªembeddingå¤±è´¥: {str(e)}")
            return [0.0] * settings.embedding_dimension

    async def add_documents(self, documents: List[Dict[str, Any]]) -> List[str]:
        """æ·»åŠ æ–‡æ¡£åˆ°æœç´¢ç´¢å¼•"""
        try:
            # ç¡®ä¿ç´¢å¼•å­˜åœ¨
            await self.ensure_index_exists()

            # å‡†å¤‡æ–‡æ¡£æ•°æ®
            search_documents = []
            doc_ids = []

            for doc in documents:
                doc_id = str(uuid.uuid4())
                doc_ids.append(doc_id)

                # ç”Ÿæˆå†…å®¹å‘é‡
                content = doc.get("content", "")
                content_vector = await self.generate_single_embedding(content)

                search_doc = {
                    "id": doc_id,
                    "content": content,
                    "content_vector": content_vector,
                    "title": doc.get("title", ""),
                    "file_path": doc.get("file_path", ""),
                    "chunk_index": doc.get("chunk_index", 0),
                    "quality_score": doc.get("quality_score", 0.0),
                    "created_at": datetime.utcnow().isoformat() + "Z",
                    "metadata": json.dumps(doc.get("metadata", {}))
                }
                search_documents.append(search_doc)

            # æ‰¹é‡ä¸Šä¼ æ–‡æ¡£
            result = self.search_client.upload_documents(search_documents)

            successful_uploads = [doc_id for doc_id, success in zip(doc_ids, result) if success.succeeded]
            print(f"âœ… æˆåŠŸä¸Šä¼  {len(successful_uploads)}/{len(documents)} ä¸ªæ–‡æ¡£åˆ°æœç´¢ç´¢å¼•")

            return successful_uploads

        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡æ¡£åˆ°æœç´¢ç´¢å¼•å¤±è´¥: {str(e)}")
            return []

    async def search_documents(
        self,
        query: str,
        top_k: int = 5,
        min_score: float = 0.7,
        use_semantic_search: bool = True
    ) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vector = await self.generate_single_embedding(query)

            # åˆ›å»ºå‘é‡æŸ¥è¯¢
            vector_query = VectorizedQuery(
                vector=query_vector,
                k_nearest_neighbors=top_k,
                fields="content_vector"
            )

            # æ‰§è¡Œæœç´¢
            search_params = {
                "search_text": query if use_semantic_search else None,
                "vector_queries": [vector_query],
                "select": ["id", "content", "title", "file_path", "chunk_index", "quality_score", "metadata"],
                "top": top_k,
            }

            if use_semantic_search:
                search_params["query_type"] = "semantic"
                search_params["semantic_configuration_name"] = "my-semantic-config"
                search_params["query_caption"] = "extractive"
                search_params["query_answer"] = "extractive"

            results = self.search_client.search(**search_params)

            # å¤„ç†æœç´¢ç»“æœ
            documents = []
            for result in results:
                # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
                score = result.get("@search.score", 0.0)
                if score >= min_score:
                    documents.append({
                        "id": result["id"],
                        "content": result["content"],
                        "title": result["title"],
                        "file_path": result["file_path"],
                        "chunk_index": result["chunk_index"],
                        "quality_score": result["quality_score"],
                        "similarity": score,
                        "metadata": json.loads(result.get("metadata", "{}")),
                        "captions": result.get("@search.captions", []),
                        "answers": result.get("@search.answers", [])
                    })

            print(f"ğŸ” æ‰¾åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£ï¼Œåˆ†æ•°é˜ˆå€¼: {min_score}")
            return documents

        except Exception as e:
            print(f"âŒ æœç´¢æ–‡æ¡£å¤±è´¥: {str(e)}")
            return []

    async def delete_documents_by_file(self, file_path: str) -> bool:
        """åˆ é™¤æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰æ–‡æ¡£"""
        try:
            # æœç´¢è¯¥æ–‡ä»¶çš„æ‰€æœ‰æ–‡æ¡£
            results = self.search_client.search(
                search_text="*",
                filter=f"file_path eq '{file_path}'",
                select=["id"]
            )

            # è·å–æ–‡æ¡£IDåˆ—è¡¨
            doc_ids = [result["id"] for result in results]

            if not doc_ids:
                print(f"æœªæ‰¾åˆ°æ–‡ä»¶ {file_path} çš„æ–‡æ¡£")
                return True

            # åˆ é™¤æ–‡æ¡£
            delete_docs = [{"id": doc_id} for doc_id in doc_ids]
            result = self.search_client.delete_documents(delete_docs)

            successful_deletes = sum(1 for r in result if r.succeeded)
            print(f"âœ… æˆåŠŸåˆ é™¤ {successful_deletes}/{len(doc_ids)} ä¸ªæ–‡æ¡£")

            return successful_deletes == len(doc_ids)

        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")
            return False

    async def get_index_stats(self) -> Dict[str, Any]:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–æ–‡æ¡£æ€»æ•°
            results = self.search_client.search(
                search_text="*",
                include_total_count=True,
                top=0
            )

            total_docs = results.get_count()

            # è·å–ç´¢å¼•ä¿¡æ¯
            index_info = self.index_client.get_index(settings.azure_search_index_name)

            return {
                "index_name": settings.azure_search_index_name,
                "total_documents": total_docs,
                "index_size": index_info.name,
                "embedding_dimension": settings.embedding_dimension,
                "created_at": datetime.utcnow().isoformat()
            }

        except Exception as e:
            print(f"âŒ è·å–ç´¢å¼•ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}

    async def clear_index(self) -> bool:
        """æ¸…ç©ºç´¢å¼•ä¸­çš„æ‰€æœ‰æ–‡æ¡£"""
        try:
            # è·å–æ‰€æœ‰æ–‡æ¡£ID
            results = self.search_client.search(
                search_text="*",
                select=["id"]
            )

            doc_ids = [result["id"] for result in results]

            if not doc_ids:
                print("ç´¢å¼•ä¸­æ²¡æœ‰æ–‡æ¡£éœ€è¦æ¸…ç©º")
                return True

            # æ‰¹é‡åˆ é™¤æ–‡æ¡£
            delete_docs = [{"id": doc_id} for doc_id in doc_ids]
            result = self.search_client.delete_documents(delete_docs)

            successful_deletes = sum(1 for r in result if r.succeeded)
            print(f"âœ… æˆåŠŸæ¸…ç©ºç´¢å¼•ï¼Œåˆ é™¤äº† {successful_deletes} ä¸ªæ–‡æ¡£")

            return successful_deletes == len(doc_ids)

        except Exception as e:
            print(f"âŒ æ¸…ç©ºç´¢å¼•å¤±è´¥: {str(e)}")
            return False


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
azure_search_service = AzureSearchService()